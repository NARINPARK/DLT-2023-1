{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "56373dfd",
   "metadata": {},
   "source": [
    "# DLT Project Report\n",
    "### Model comparison for LSTM and Feedfoward with timseries data set\n",
    "###### 성균관대 통계학과 박나린 (석사) 2022711906\n",
    "\n",
    "## 0. Setting\n",
    "\n",
    "케라스 기반의 딥러닝 모델들을 쓰기 위한 기본 환경 설정을 해준다. 또한 파이썬 기반의 모형들을 쓰기 때문에, 파이썬에서 처리를 위한 패키지들도 불러 와준다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3706862e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import bz2\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import models, layers, optimizers\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer, text_to_word_sequence\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3e40fda1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/annie/Dropbox/data/input\\test.ft.txt.bz2\n",
      "C:/Users/annie/Dropbox/data/input\\train.ft.txt.bz2\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "for dirname, _, filenames in os.walk('C:/Users/annie/Dropbox/data/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef057b17",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36a592f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4fe13b9c",
   "metadata": {},
   "source": [
    "## 1. Data Processing\n",
    "\n",
    "이 데이터셋은 fastText를 학습하기 위한 아마존 고객 리뷰 몇 백만 개(입력 텍스트)와 별점(출력 레이블)으로 구성되어 있다. \n",
    "이 데이터셋은 양질의 비즈니스 데이터로 실제 규모이지만, 소규모 노트북에서 몇 분 안에 학습할 수 있도록 구성되었다. train 과 test 파일이 각각 존재 하므로 train test를 나눌 필요가 없다.\n",
    "\n",
    "### 1.1 Import Data\n",
    "먼저 bz2 파일 형식으로 되어있는 train, test 파일을 불러온다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9a68f897",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bz2 데이터 읽어 오는 def 만들어주기\n",
    "\n",
    "def labels_texts(file):\n",
    "    labels = []\n",
    "    texts = []\n",
    "    for line in bz2.BZ2File(file):\n",
    "        x = line.decode(\"utf-8\")\n",
    "        labels.append(int(x[9]) - 1)\n",
    "        texts.append(x[10:].strip())\n",
    "    return np.array(labels), texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5f4ae891",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_label, train_text = labels_texts('C:/Users/annie/Dropbox/data/input/train.ft.txt.bz2')\n",
    "test_label, test_text = labels_texts('C:/Users/annie/Dropbox/data/input/test.ft.txt.bz2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "20499dc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "Stuning even for the non-gamer: This sound track was beautiful! It paints the senery in your mind so well I would recomend it even to people who hate vid. game music! I have played the game Chrono Cross but out of all of the games I have ever played it has the best music! It backs away from crude keyboarding and takes a fresher step with grate guitars and soulful orchestras. It would impress anyone who cares to listen! ^_^\n"
     ]
    }
   ],
   "source": [
    "print(train_label[0])\n",
    "print(train_text[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ca6e0b8",
   "metadata": {},
   "source": [
    "\n",
    "텍스트를 처리하기 위해 첫 번째로 수행할 작업은 모든 문자를 소문자로 변환하고, 단어가 아닌 문자를 제거 하는 것이다. 대부분의 경우 이는 구두점으로 대체될 것이다. 그런 다음, 강세 기호가 있는 문자와 같은 다른 문자를 제거한다.. 이러한 문자들 중 일부는 정규 ASCII 문자로 대체하는 것이 더 좋을 수도 있지만, 여기서는 그것을 무시하기로 결정했다. 또한, 이 코퍼스에서는 다양한 문자의 빈도를 살펴보면 매우 적은 수의 특이한 문자가 있는 것으로 나타났다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f3bf721a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "not_numChar = re.compile(r'[\\W]')\n",
    "no_encode = re.compile(r'[^a-z0-1\\s]')\n",
    "\n",
    "def normalisation(texts):\n",
    "    norm_text = []\n",
    "    for word in texts:\n",
    "        lower = word.lower()\n",
    "        not_punct = not_numChar.sub(r' ', lower)\n",
    "        exclude_no_encode = no_encode.sub(r'', not_punct)\n",
    "        norm_text.append(exclude_no_encode)\n",
    "    return norm_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "593604d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_text = normalisation(train_text)\n",
    "test_text = normalisation(test_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "542c193e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stuning even for the non gamer  this sound track was beautiful  it paints the senery in your mind so well i would recomend it even to people who hate vid  game music  i have played the game chrono cross but out of all of the games i have ever played it has the best music  it backs away from crude keyboarding and takes a fresher step with grate guitars and soulful orchestras  it would impress anyone who cares to listen    \n"
     ]
    }
   ],
   "source": [
    "print(train_text[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35f3576c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "72e68ec0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3600000,)\n",
      "(400000,)\n"
     ]
    }
   ],
   "source": [
    "y_train = np.array(train_label)\n",
    "y_test = np.array(test_label)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5094ebdb",
   "metadata": {},
   "source": [
    "### 1.2 Tokenize the data\n",
    "\n",
    "토크나이즈(tokenize)는 텍스트를 작은 단위로 분할하는 과정으로 토크나이즈를 통해 텍스트를 단어 단위로 분할하면 자연어 처리 작업에 대해 더욱 정확한 분석이 가능해진다. 각각의 단어는 개별적인 의미를 가지며, 이를 활용하여 문장 또는 문서의 의미를 파악하거나 감성 분석과 같은 작업을 수행할 수 있는 구조를 뛰게 해준다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "53a31435",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_features = 8192 # We will only consider the top 10,000 words in the dataset\n",
    "maxlen = 128  # We will cut reviews after 128 words\n",
    "embed_size = 64  \n",
    "\n",
    "tokenizer = Tokenizer(num_words=max_features)\n",
    "tokenizer.fit_on_texts(train_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "08e2d42f",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_token = tokenizer.texts_to_sequences(train_text)\n",
    "testing_token = tokenizer.texts_to_sequences(test_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "35fc33b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = pad_sequences(training_token, maxlen = maxlen, padding = 'post')\n",
    "x_test = pad_sequences(testing_token, maxlen = maxlen, padding = 'post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88a19081",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8b8cc1e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c3e4320",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2b9d9a08",
   "metadata": {},
   "source": [
    "# 2. Model Fitting\n",
    "## 2.1 CNN\n",
    "\n",
    "\n",
    "CNN은 \"Convolutional Neural Network\"의 약자로, 합성곱 신경망이라고도 불린다. 이는 주로 이미지 및 시계열 데이터와 같은 그리드 형식의 입력에 사용되는 신경망 아키텍처로 특히 이미지 인식, 컴퓨터 비전 및 자연어 처리와 관련된 작업에 많이 사용된다.\n",
    "\n",
    "CNN은 입력 데이터의 지역적인 패턴 및 구조를 인식하기 위해 컨볼루션 연산을 사용하는데 이는 입력 데이터를 작은 윈도우로 나누고, 각 윈도우에 대해 필터와의 컨볼루션을 계산하는 것을 의미한다. 이러한 컨볼루션 연산은 데이터의 특징을 추출하는 데 도움이 된다. 컨볼루션 연산의 결과는 활성화 함수를 통과한 뒤, 풀링(pooling) 레이어를 통해 다운샘플링 되고, 이 과정을 반복하여 신경망은 점차 더 추상적인 수준의 특징을 학습하게 되는 것이다.\n",
    "\n",
    "CNN은 이러한 컨볼루션 및 풀링 레이어의 조합으로 구성되며, 일반적으로 여러 개의 컨볼루션 레이어와 풀링 레이어가 번갈아가며 쌓이는 형태를 가지고 있다. 이후에는 전체 특징 맵을 완전 연결(fully connected) 레이어로 연결하여 최종 분류를 수행하게 된다.\n",
    "\n",
    "CNN은 이미지 처리 작업에서 좋은 성능을 보이며, 최근에는 자연어 처리 작업에도 적용되고 있다. 텍스트 분류, 감성 분석, 문장 생성 등의 자연어 처리 작업에서 CNN은 텍스트의 지역적인 구조와 패턴을 학습하여 효과적인 모델을 구축하는 데 도움이 된다.\n",
    "\n",
    "따라서 먼저 CNN구조의 신경망을 사용하여 모델 적합을 해보기로 하였다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e8d4cb90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 128)]             0         \n",
      "                                                                 \n",
      " embedding (Embedding)       (None, 128, 64)           524288    \n",
      "                                                                 \n",
      " conv1d (Conv1D)             (None, 126, 64)           12352     \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 126, 64)          256       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " max_pooling1d (MaxPooling1D  (None, 42, 64)           0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           (None, 38, 64)            20544     \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 38, 64)           256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling1d_1 (MaxPooling  (None, 7, 64)            0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " conv1d_2 (Conv1D)           (None, 3, 64)             20544     \n",
      "                                                                 \n",
      " global_max_pooling1d (Globa  (None, 64)               0         \n",
      " lMaxPooling1D)                                                  \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 64)                0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 100)               6500      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 101       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 584,841\n",
      "Trainable params: 584,585\n",
      "Non-trainable params: 256\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def build_model():\n",
    "    sequences = layers.Input(shape=(maxlen,))\n",
    "    embedded = layers.Embedding(max_features, 64)(sequences)\n",
    "    x = layers.Conv1D(64, 3, activation='relu')(embedded)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.MaxPool1D(3)(x)\n",
    "    x = layers.Conv1D(64, 5, activation='relu')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.MaxPool1D(5)(x)\n",
    "    x = layers.Conv1D(64, 5, activation='relu')(x)\n",
    "    x = layers.GlobalMaxPool1D()(x)\n",
    "    x = layers.Flatten()(x)\n",
    "    x = layers.Dense(100, activation='relu')(x)\n",
    "    predictions = layers.Dense(1, activation='sigmoid')(x)\n",
    "    model = models.Model(inputs=sequences, outputs=predictions)\n",
    "    model.compile(\n",
    "        optimizer='rmsprop',\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['binary_accuracy']\n",
    "    )\n",
    "    return model\n",
    "    \n",
    "model = build_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3efdcef8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "56250/56250 [==============================] - 2710s 48ms/step - loss: 0.1860 - binary_accuracy: 0.9286 - val_loss: 0.1660 - val_binary_accuracy: 0.9378\n",
      "Epoch 2/2\n",
      "56250/56250 [==============================] - 2557s 45ms/step - loss: 0.1638 - binary_accuracy: 0.9388 - val_loss: 0.1649 - val_binary_accuracy: 0.9383\n"
     ]
    }
   ],
   "source": [
    "history=model.fit( x_train, y_train, batch_size=64, epochs=2, validation_data=(x_test, y_test),)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8e83e533",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'acc'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m acc \u001b[38;5;241m=\u001b[39m \u001b[43mhistory\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhistory\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43macc\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[0;32m      4\u001b[0m val_acc \u001b[38;5;241m=\u001b[39m history\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_acc\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m      5\u001b[0m loss \u001b[38;5;241m=\u001b[39m history\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\u001b[1;31mKeyError\u001b[0m: 'acc'"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cd2d4d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict(test_texts)\n",
    "print('Accuracy score: {:0.4}'.format(accuracy_score(test_labels, 1 * (preds > 0.5))))\n",
    "print('F1 score: {:0.4}'.format(f1_score(test_labels, 1 * (preds > 0.5))))\n",
    "print('ROC AUC score: {:0.4}'.format(roc_auc_score(test_labels, preds)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba6adbe9",
   "metadata": {},
   "source": [
    "## 2.2 RNN\n",
    "\n",
    "RNN은 \"Recurrent Neural Network\"의 약자로, 순환 신경망이라고도 불린다. 이는 주로 시퀀스 데이터를 처리하는 데 사용되는 신경망 아키텍로, 이전 단계에서 계산된 결과를 현재 단계의 입력으로 반복적으로 전달하여 순환적인 구조를 형성한다.\n",
    "\n",
    "RNN은 시퀀스 데이터의 특성을 이해하기 위해 시간적인 정보를 고려하여 각 단계에서 RNN은 현재 입력과 이전 단계의 은닉 상태를 함께 출력을 계산한다. 이전 단계의 정보가 현재 단계로 전달되기 때문에 RNN은 시퀀스의 장기 의존성을 학습할 수 있고 이러한 특성은 자연어 처리와 음성 인식과 같은 작업에 유용하게 된다.\n",
    "\n",
    "RNN은 기본적으로 동일한 가중치를 모든 시간 단계에서 재사용하며, 재귀적인 구조를 가지고 있기 때문에 오래된 정보를 유지하면서 새로운 입력에 대한 정보를 반영할 수 있다. 그러나 RNN에는 \"장기 의존성 문제\"가 있어, 긴 시퀀스에서는 이전 정보를 제대로 기억하지 못하는 경우가 발생할 수 있다.\n",
    "\n",
    "이러한 문제를 해결하기 위해 LSTM(Long Short-Term Memory)과 GRU(Gated Recurrent Unit)와 같은 RNN의 변형 모델이 개발되었고. LSTM과 GRU는 RNN의 기본 구조를 확장하여 장기 의존성을 더 잘 학습할 수 있도록 도와준다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa3ce5e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_rnn_model():\n",
    "    sequences = layers.Input(shape=(maxlen,))\n",
    "    embedded = layers.Embedding(max_features, 64)(sequences)\n",
    "    x = layers.RNN(128, return_sequences=True)(embedded)\n",
    "    x = layers.RNN(128)(x)\n",
    "    x = layers.Dense(32, activation='relu')(x)\n",
    "    x = layers.Dense(100, activation='relu')(x)\n",
    "    predictions = layers.Dense(1, activation='sigmoid')(x)\n",
    "    model2 = models.Model(inputs=sequences, outputs=predictions)\n",
    "    model2.compile(\n",
    "        optimizer='rmsprop',\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['binary_accuracy']\n",
    "    )\n",
    "    return model2\n",
    "    \n",
    "rnn_model = build_rnn_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c762a92e",
   "metadata": {},
   "outputs": [],
   "source": [
    "history=rnn_model.fit(train_texts, train_labels,  batch_size=128, epochs=1, validation_data=(x_test, y_test), )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "592c9862",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38fcd831",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab7f5001",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "155bc577",
   "metadata": {},
   "source": [
    "## 2.3 LSTM\n",
    "\n",
    "LSTM은 \"Long Short-Term Memory\"의 약자로, RNN의 변형 중 하나이다. LSTM은 RNN의 단점인 장기 의존성 문제를 해결하고자 고안되었다. 장기 의존성 문제란, RNN이 긴 시퀀스에서 이전 정보를 적절하게 기억하지 못하는 문제를 의미한다.\n",
    "\n",
    "LSTM은 이 문제를 해결하기 위해 게이트 매커니즘을 도입했는데, 입력 게이트, 삭제 게이트, 출력 게이트 등의 게이트를 사용하여 이전 정보를 얼마나 기억하고 얼마나 새로운 정보를 반영할지를 조절하게 된다. 이를 통해 LSTM은 긴 시퀀스에서도 장기적인 의존성을 학습할 수 있다.\n",
    "\n",
    "LSTM은 감성 분석과 같은 NLP 작업에 유용하게 사용된다. 오냐하면 LSTM이 시퀀스 데이터를 처리하고 문맥 정보를 유지하면서 텍스트의 감정 표현을 이해하는 데 도움이 되기 때문입니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a3018b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_LSTM_model():\n",
    "    sequences = layers.Input(shape=(maxlen,))\n",
    "    embedded = layers.Embedding(max_features, 64)(sequences)\n",
    "    x = layers.LSTM(128, return_sequences=True)(embedded)\n",
    "    x = layers.LSTM(128)(x)\n",
    "    x = layers.Dense(32, activation='relu')(x)\n",
    "    x = layers.Dense(100, activation='relu')(x)\n",
    "    predictions = layers.Dense(1, activation='sigmoid')(x)\n",
    "    model2 = models.Model(inputs=sequences, outputs=predictions)\n",
    "    model2.compile(\n",
    "        optimizer='rmsprop',\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['binary_accuracy']\n",
    "    )\n",
    "    return model2\n",
    "\n",
    "lstm_model = build_LSTM_model()\n",
    " \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0067929",
   "metadata": {},
   "outputs": [],
   "source": [
    "history_lstm=lstm_model.fit(train_texts, train_labels,  batch_size=128, epochs=1, validation_data=(x_test, y_test), )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b42e68b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2844444",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb39ad70",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.image  as mpimg\n",
    "\n",
    "#-----------------------------------------------------------\n",
    "# Retrieve a list of list results on training and test data\n",
    "# sets for each training epoch\n",
    "#-----------------------------------------------------------\n",
    "acc=history_lstm.history['accuracy']\n",
    "val_acc=history_lstm.history['val_accuracy']\n",
    "loss=history_lstm.history['loss']\n",
    "val_loss=history_lstm.history['val_loss']\n",
    "\n",
    "epochs=range(len(acc)) # Get number of epochs\n",
    "\n",
    "#------------------------------------------------\n",
    "# Plot training and validation accuracy per epoch\n",
    "#------------------------------------------------\n",
    "plt.plot(epochs, acc, 'r')\n",
    "plt.plot(epochs, val_acc, 'b')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend([\"Accuracy\", \"Validation Accuracy\"])\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "#------------------------------------------------\n",
    "# Plot training and validation loss per epoch\n",
    "#------------------------------------------------\n",
    "plt.plot(epochs, loss, 'r')\n",
    "plt.plot(epochs, val_loss, 'b')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend([\"Loss\", \"Validation Loss\"])\n",
    "\n",
    "plt.figure()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c47d7875",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b08570ba",
   "metadata": {},
   "source": [
    "## 2.4 CNN+LSTM\n",
    "\n",
    "\n",
    "CNN과 LSTM을 결합한 모델은 CNN-LSTM 모델이라고 불리며, 이미지나 텍스트와 같은 시퀀스 데이터에 대해 효과적인 모델이다. 이 모델은 CNN 레이어를 통해 특징 추출을 수행하고, 추출된 특징을 LSTM 레이어로 전달하여 시퀀스적인 특징을 학습하여 시간적인 의존성과 지역적인 구조 모두를 이해할 수 있다. CNN-LSTM 모델은 자연어 처리, 영상 분류, 행동 인식 등 다양한 작업에 활용되고 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1c41718c",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Input' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 24\u001b[0m\n\u001b[0;32m     18\u001b[0m     model\u001b[38;5;241m.\u001b[39mcompile(loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbinary_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     19\u001b[0m                   optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     20\u001b[0m                   metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbinary_accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m     22\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m model\n\u001b[1;32m---> 24\u001b[0m cudnnlstm_model \u001b[38;5;241m=\u001b[39m \u001b[43mcudnnlstm_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     25\u001b[0m cudnnlstm_model\u001b[38;5;241m.\u001b[39msummary()\n",
      "Cell \u001b[1;32mIn[16], line 2\u001b[0m, in \u001b[0;36mcudnnlstm_model\u001b[1;34m(conv_layers, max_dilation_rate)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcudnnlstm_model\u001b[39m(conv_layers \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m, max_dilation_rate \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m3\u001b[39m):\n\u001b[1;32m----> 2\u001b[0m     inp \u001b[38;5;241m=\u001b[39m \u001b[43mInput\u001b[49m(shape\u001b[38;5;241m=\u001b[39m(maxlen, ))\n\u001b[0;32m      3\u001b[0m     x \u001b[38;5;241m=\u001b[39m Embedding(max_features, embed_size, weights\u001b[38;5;241m=\u001b[39m[embedding_matrix], trainable\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)(inp)\n\u001b[0;32m      4\u001b[0m     x \u001b[38;5;241m=\u001b[39m Dropout(\u001b[38;5;241m0.25\u001b[39m)(x)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Input' is not defined"
     ]
    }
   ],
   "source": [
    "def cudnnlstm_model(conv_layers = 2, max_dilation_rate = 3):\n",
    "    inp = layers.Input(shape=(maxlen, ))\n",
    "    x = Embedding(max_features, embed_size, weights=[embedding_matrix], trainable=True)(inp)\n",
    "    x = Dropout(0.25)(x)\n",
    "    x = Conv1D(2*embed_size, kernel_size = 3)(x)\n",
    "    prefilt = Conv1D(2*embed_size, kernel_size = 3)(x)\n",
    "    x = prefilt\n",
    "    for strides in [1, 1, 2]:\n",
    "        x = layers.Conv1D(128*2**(strides), strides = strides, kernel_regularizer=l2(4e-6), bias_regularizer=l2(4e-6), kernel_size=3, kernel_constraint=maxnorm(10), bias_constraint=maxnorm(10))(x)\n",
    "    x_f = layers.CuDNNLSTM(512, kernel_regularizer=l2(4e-6), bias_regularizer=l2(4e-6), kernel_constraint=maxnorm(10), bias_constraint=maxnorm(10))(x)  \n",
    "    x_b = layers.CuDNNLSTM(512, kernel_regularizer=l2(4e-6), bias_regularizer=l2(4e-6), kernel_constraint=maxnorm(10), bias_constraint=maxnorm(10))(x)\n",
    "    x = concatenate([x_f, x_b])\n",
    "    x = layers.Dropout(0.5)(x)\n",
    "    x = layers.Dense(64, activation=\"relu\")(x)\n",
    "    x = layers.Dropout(0.1)(x)\n",
    "    x = layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "    model = models.Model(inputs=inp, outputs=x)\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer='adam',\n",
    "                  metrics=['binary_accuracy'])\n",
    "\n",
    "    return model\n",
    "\n",
    "cudnnlstm_model = cudnnlstm_model()\n",
    "cudnnlstm_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0292eeae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1055136",
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_path=\"early_weights.hdf5\"\n",
    "checkpoint = ModelCheckpoint(weight_path, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "early_stopping = EarlyStopping(monitor=\"val_loss\", mode=\"min\", patience=5)\n",
    "callbacks = [checkpoint, early_stopping]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29a059ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "cudnnlstm_model.fit(X_train, train_labels, batch_size=batch_size, epochs=epochs, shuffle = True, validation_split=0.20, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03a93fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "cudnnlstm_model.load_weights(weight_path)\n",
    "score, acc = cudnnlstm_model.evaluate(x_test, y_test, batch_size=batch_size)\n",
    "print('Test score:', score)\n",
    "print('Test accuracy:', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "553ba1b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6dd87dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e579208f",
   "metadata": {},
   "source": [
    "## 3. Conclusion\n",
    "\n",
    "keras기반의 다양한 모델을 통해 텍스트 분석을 실시 해보았다. 결과는 순서로 좋았음을 알수 있다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34c53755",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b327ce8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52980e4c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e983192",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7371f77",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
